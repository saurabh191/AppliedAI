{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation of Performance metric class to solve problem A, B, C and D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm #Importing tqdm for visual representation of progress\n",
    "\n",
    "class PerformanceMatrix:\n",
    "    def __init__(self,df):\n",
    "        self.setVariables()\n",
    "        self.df = df\n",
    "    \n",
    "    def setVariables(self):\n",
    "        self._truePositive = 0\n",
    "        self._trueNegative = 0\n",
    "        self._falsePositive = 0\n",
    "        self._falseNegtive = 0\n",
    "        self._cnf_matrix = []\n",
    "        \n",
    "    def predict(self,threshold):\n",
    "        self.df[\"ypred\"] = [1 if x > threshold else 0 for x in self.df[\"proba\"]] \n",
    "\n",
    "        \n",
    "    def confusion_matrix(self):\n",
    "        \"\"\"This method returns the confusion matrix for the given pair of Y and Y_Predicted\"\"\"       \n",
    "        #y,ypred\n",
    "        y = self.df[\"y\"]\n",
    "        ypred = self.df[\"ypred\"]\n",
    "        self.setVariables()\n",
    "        prob = self.df[\"proba\"]\n",
    "        \n",
    "        try:\n",
    "            assert len(y) == len(ypred)\n",
    "            for val in range(len(prob)):\n",
    "                if y[val] == 1 and ypred[val] == 1:\n",
    "                    self._truePositive +=1\n",
    "                if y[val] == 1 and ypred[val] == 0:\n",
    "                    self._trueNegative +=1\n",
    "                if y[val] == 0 and ypred[val] == 1:\n",
    "                    self._falsePositive +=1\n",
    "                if y[val] == 0 and ypred[val] == 0:\n",
    "                    self._falseNegtive +=1\n",
    "            for i in self._truePositive,self._trueNegative,self._falsePositive,self._falseNegtive:\n",
    "                self._cnf_matrix.append(i)\n",
    "            cnfMatrix = self._cnf_matrix.copy()\n",
    "                \n",
    "            return np.array(cnfMatrix).reshape(2,2)\n",
    "  \n",
    "        except AssertionError:\n",
    "            print(\"Input Error: Length of y and ypred is not same.\")\n",
    "            \n",
    "    def f1_score(self):\n",
    "        \"\"\"This method returns the f1_score for the given pair of Y and  Y_Predicted\"\"\"  \n",
    "        _precision = ((self._truePositive)/(self._truePositive+self._falsePositive))\n",
    "        _recall = ((self._truePositive)/(self._falseNegtive+self._truePositive))\n",
    "        f1Score = (2*((_precision*_recall)/(_precision+_recall)))\n",
    "        return f1Score   \n",
    "    \n",
    "    def acuracy(self):\n",
    "        \"\"\"This method return the accuracy of a model for a given pair of Y and  Y_Predicted\"\"\"        \n",
    "        totalNumberofPoints = len(self.df[\"y\"])\n",
    "        _accuracy = self._truePositive/totalNumberofPoints\n",
    "        return _accuracy\n",
    "    \n",
    "    def auc_score(self):\n",
    "        \"\"\"This method returns the AUC score\"\"\"\n",
    "        totalPositiveCount = self._falseNegtive + self._truePositive\n",
    "        totalNegativeCount = self._falsePositive + self._trueNegative\n",
    "        truePositiveRate = []\n",
    "        falsePositiveRate = []\n",
    "        prob = self.df[\"proba\"]\n",
    "        self.df=self.df.sort_values(by='proba',ascending=False)\n",
    "        self.df.drop(columns=['ypred'],inplace=True)\n",
    "        \n",
    "        for item in tqdm(prob):\n",
    "            self.predict(item)\n",
    "            cnf = self.confusion_matrix()\n",
    "            truePositiveRate.append(int(self._cnf_matrix[3])/totalPositiveCount)\n",
    "            falsePositiveRate.append(int(self._cnf_matrix[2])/totalNegativeCount)\n",
    "            self.df.drop(columns=[\"ypred\"])\n",
    "\n",
    "        return np.trapz(truePositiveRate,falsePositiveRate)\n",
    "    \n",
    "    def metricForLowestValues(self):\n",
    "        \"\"\"Compute the best threshold of probability which gives lowest values of metric A\"\"\"\n",
    "        dict_metricA = {}\n",
    "        prob = self.df[\"proba\"]\n",
    "\n",
    "        for item in tqdm(prob):\n",
    "            self.predict(item)\n",
    "            cnf = self.confusion_matrix()\n",
    "            # A=500×number of false negative+100×numebr of false positive\n",
    "            metricA = 500 * self._falseNegtive + 100* self._falsePositive\n",
    "            dict_metricA[item] = metricA\n",
    "            self.df.drop(columns=[\"ypred\"],inplace=True)\n",
    "        sorted_metricAList = sorted(dict_metricA.items(),key=lambda item:item[1])\n",
    "        minKey = sorted_metricAList[0][0]\n",
    "        minValue = dict_metricA[minKey]\n",
    "\n",
    "        return minKey, minValue\n",
    "    \n",
    "    def meanSquaredError(self):\n",
    "        \"\"\"This module calcutes the mean square error\"\"\"\n",
    "        y = self.df[\"y\"]\n",
    "        ypred = self.df[\"ypred\"]\n",
    "        return np.square(np.subtract(y,ypred)).mean()\n",
    "    \n",
    "    def calculateMAPE(self):\n",
    "        \"\"\"This method return the Modified MAPE (Mean Absolute Percentage Error)\"\"\"\n",
    "        y = self.df[\"y\"]\n",
    "        ypred = self.df[\"ypred\"]\n",
    "        actual = y.sum()\n",
    "        absError = np.absolute(y - ypred).sum()\n",
    "        return absError/actual\n",
    "         \n",
    "    \n",
    "    def _totalSumOfSquared(self,y,ymean):\n",
    "        ssTo = np.square(y - ymean).sum()\n",
    "        return ssTo\n",
    "    \n",
    "    def _residualSumOfSquared(self,y,ypred):\n",
    "        ssRes = np.square(y - ypred).sum()\n",
    "        return ssRes\n",
    "    \n",
    "    def R_SquaredError(self):\n",
    "        \"This method calculates the Coefficient of Determination-R2 score\"\n",
    "        ymean = self.df[\"y\"].mean()\n",
    "        y = self.df[\"y\"]\n",
    "        ypred = self.df[\"ypred\"]\n",
    "        _SSres = self._residualSumOfSquared(y,ypred)\n",
    "        _SSto = self._totalSumOfSquared(y,ymean)\n",
    "        _R2 = (1-(_SSres/_SSto))\n",
    "        return _R2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution for Problem 'A'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100, 2)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"5_a.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = PerformanceMatrix(df)\n",
    "performance.predict(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10000,     0],\n",
       "       [  100,     0]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950248756218906"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900990099009901"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.acuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10100/10100 [2:03:17<00:00,  1.37it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004999999999999999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.auc_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution for Problem 'B'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100, 2)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code\n",
    "df2 = pd.read_csv(\"5_b.csv\")\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance2 = PerformanceMatrix(df2)\n",
    "performance2.predict(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  55,   45],\n",
       "       [ 239, 9761]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance2.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010880316518298714"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance2.f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005445544554455445"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance2.acuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10100/10100 [9:46:37<00:00,  3.48s/it]      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.93564957901443"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance2.auc_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution for Problem 'C'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2852, 2)\n"
     ]
    }
   ],
   "source": [
    "# write your code\n",
    "df3=pd.read_csv('5_c.csv')\n",
    "df3.columns = [\"y\", \"proba\"]\n",
    "print(df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance3 = PerformanceMatrix(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:12<00:00,  6.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02803798623987141, 180900)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance3.metricForLowestValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
    "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution for Problem 'D'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157200, 2)\n"
     ]
    }
   ],
   "source": [
    "# write your code\n",
    "df4=pd.read_csv('5_d.csv')\n",
    "df4.columns = [\"y\", \"ypred\"]\n",
    "print(df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.16569974554707"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance4 = PerformanceMatrix(df4)\n",
    "performance4.meanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1291202994009687"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance4.calculateMAPE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9563582786990937"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance4.R_SquaredError()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
